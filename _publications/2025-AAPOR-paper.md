---
title: "Evaluating the Efficacy of LLM-Augmented Imputation in Longitudinal SurveysEvaluating the Efficacy of LLM-Augmented Imputation in Longitudinal Surveys"
collection: publications
category: conferences
permalink: /publication/2025-AAPOR-paper
excerpt: 'Longitudinal surveys are essential for data collection in social sciences, economics, health, and public policy, offering valuable insights into trends over time and motivating evidence-based policy making. However, declining response rates in major U.S. surveys, like the Current Population Survey (CPS) and American Community Survey (ACS), raise concerns about data accuracy and representativeness. Declines resulting largely from attrition undermine the representativeness and validity of longitudinal datasets. Traditional imputation techniques, such as multiple imputation, hot-deck imputation, and inverse probability weighting, are common methods used to address nonresponse. Yet, recent advances in artificial intelligence (AI) and machine learning (ML) offer promising new strategies, especially for handling complex nonresponse patterns. For example, large language models (LLMs) permit analysts to generate synthetic personas to better represent respondent groups and may provide a more accurate reflection of the target population. In this research, we train the open source LLM ChatGPT 4o on respondent demographic information and previous responses from the four waves of the 2014 Survey of Program Participation (SIPP) and impute missing responses in each wave. This approach enables us to evaluate the effectiveness of LLMs to impute missing responses, particularly in federally-administered program participation data (such as SNAP, WIC, TANF, Medicaid/Medicare), where attrition in longitudinal surveys significantly impacts data quality. Our preliminary work shows that LLMs provide a meaningful candidate to impute missing data in the context of the SIPP. Using trained personas through LLMs provide a transparent method to develop imputed values, mimicking how traditional person interviews function. Further research will involve evaluating the imputations and developing new respondent weights to enable longitudinal analysis that combines reported and imputed data.'
date: 2025-05-15
venue: 'Preecidings of 80th Annual Conference of American Association of Public Opinion Research (AAPOR)'
slidesurl: 'http://ujjayinidas.github.io/files/AAPOR2025.pdf'
citation:   'Mitra S., Das, U. & Forrester, A., (2025). Evaluating the Efficacy of LLM-Augmented Imputation in Longitudinal SurveysEvaluating the Efficacy of LLM-Augmented Imputation in Longitudinal Surveys, *AAPOR*'
---

This is a work in progress. The paper will be made available soon. Please check back later!
